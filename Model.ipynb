{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8067c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/rahib/combined_season1-40.tsv\", sep= '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "104a6d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>the Jordan</td>\n",
       "      <td>River mentioned most often in the Bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>loch</td>\n",
       "      <td>Scottish word for lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>the Missouri</td>\n",
       "      <td>American river only 33 miles shorter than the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>the Caspian Sea</td>\n",
       "      <td>World's largest lake, nearly 5 times as big as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INVENTIONS</td>\n",
       "      <td>a radio</td>\n",
       "      <td>Marconi's wonderful wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515889</th>\n",
       "      <td>INSTA-GRAHAM</td>\n",
       "      <td>Heather Graham</td>\n",
       "      <td>She describes herself on Instagram as an actre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515890</th>\n",
       "      <td>INSTA-GRAHAM</td>\n",
       "      <td>s'mores</td>\n",
       "      <td>Honey Maid Graham crackers posted a hack for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515891</th>\n",
       "      <td>INSTA-GRAHAM</td>\n",
       "      <td>Martha Graham</td>\n",
       "      <td>The official account of her dance company post...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515892</th>\n",
       "      <td>INSTA-GRAHAM</td>\n",
       "      <td>Graham Norton</td>\n",
       "      <td>He often posts about his BBC chat show &amp; his G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515893</th>\n",
       "      <td>ANCIENT ANIMALS</td>\n",
       "      <td>pterodactyls</td>\n",
       "      <td>The first fossils of these creatures with an e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515892 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               category         question  \\\n",
       "0        LAKES & RIVERS       the Jordan   \n",
       "1        LAKES & RIVERS             loch   \n",
       "2        LAKES & RIVERS     the Missouri   \n",
       "3        LAKES & RIVERS  the Caspian Sea   \n",
       "4            INVENTIONS          a radio   \n",
       "...                 ...              ...   \n",
       "515889     INSTA-GRAHAM   Heather Graham   \n",
       "515890     INSTA-GRAHAM          s'mores   \n",
       "515891     INSTA-GRAHAM    Martha Graham   \n",
       "515892     INSTA-GRAHAM    Graham Norton   \n",
       "515893  ANCIENT ANIMALS     pterodactyls   \n",
       "\n",
       "                                                   answer  \n",
       "0                 River mentioned most often in the Bible  \n",
       "1                                  Scottish word for lake  \n",
       "2       American river only 33 miles shorter than the ...  \n",
       "3       World's largest lake, nearly 5 times as big as...  \n",
       "4                            Marconi's wonderful wireless  \n",
       "...                                                   ...  \n",
       "515889  She describes herself on Instagram as an actre...  \n",
       "515890  Honey Maid Graham crackers posted a hack for m...  \n",
       "515891  The official account of her dance company post...  \n",
       "515892  He often posts about his BBC chat show & his G...  \n",
       "515893  The first fossils of these creatures with an e...  \n",
       "\n",
       "[515892 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['category', 'question', 'answer']]\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182cdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "df['clean_question'] = df['question'].apply(clean_text)\n",
    "df['clean_category'] = df['category'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0adaa7bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPasted content goes here...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = \"Pasted content goes here...\"\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10)\n",
    "keywords = vectorizer.fit([text]).get_feature_names_out()\n",
    "print(keywords)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
